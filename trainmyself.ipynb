{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import os \n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpli\n",
    "% matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as VGG_preprocess\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input as IR_preprocess\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as IV_preprocess\n",
    "\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input as X_preprocess\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, History, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam  \n",
    "               \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_tensor1(img_paths,size=(299,299)):\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    list_of_tensors = []\n",
    "    for img_path in tqdm(img_paths):\n",
    "        img = image.load_img(img_path, target_size=size)\n",
    "    # 将PIL.Image.Image类型转化为格式为(224, 224, 3)的3维张量\n",
    "        x = image.img_to_array(img)\n",
    "        list_of_tensors.append(x)\n",
    "        #list_of_tensors.append(np.expand_dims(x, axis=0))\n",
    "    # 将3维张量转化为格式为(1, 224, 224, 3)的4维张量并返回\n",
    "    #return np.expand_dims(x, axis=0)\n",
    "    return np.stack(list_of_tensors, 0)\n",
    "\n",
    "def load_train_data(path, size=(299,299)):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(10):\n",
    "        files = glob.glob(os.path.join(path, 'c'+str(i),'*.jpg'))\n",
    "        x = paths_to_tensor1(files, size=size)\n",
    "        X.extend(x)\n",
    "        y.extend([i]*len(files)) \n",
    "    #return X, y\n",
    "    #print(len(np.stack(X, 0)),len(y))\n",
    "    return np.stack(X, 0),np.asarray(y)\n",
    "\n",
    "def image_preprocess(model_name, X):\n",
    "    if model_name == 'vgg16':\n",
    "        X = VGG_preprocess(X)\n",
    "    if model_name == 'inception_v3':\n",
    "        X = IV_preprocess(X)\n",
    "    if model_name == 'inception_resnet_v2':\n",
    "        X = IR_preprocess(X)\n",
    "    if model_name == 'xception':\n",
    "        X = X_preprocess(X)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def save_model(model, cross=''):\n",
    "    json_string = model.to_json()\n",
    "    if not os.path.isdir('cache'):\n",
    "        os.mkdir('cache')\n",
    "    json_name = 'architecture_'  + cross + '.json'\n",
    "    weight_name = 'model_weights_'  + cross + '.h5'\n",
    "    open(os.path.join('cache', json_name), 'w').write(json_string)\n",
    "    model.save_weights(os.path.join('cache', weight_name), overwrite=True)\n",
    "\n",
    "def create_submission(predictions, img_names, model_name):\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'], index = img_names)\n",
    "    result1.loc['img', :] = pd.Series(img_names, index=result1.index)\n",
    "    #now = datetime.datetime.now()\n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    #suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm',model_name + 'submission.csv') \n",
    "    result1.to_csv(sub_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(b_model, n_classes = 10, set_weights = 'imagenet', locked_layers=0, input_shape=(299,299,3), include_top=False):\n",
    "    base = b_model(weights= set_weights, include_top=include_top, input_shape=input_shape)\n",
    "    fc = base.output\n",
    "    fc = GlobalAveragePooling2D()(fc)\n",
    "    fc = Dropout(0.5)(fc)\n",
    "    mypredictions = Dense(n_classes, activation='softmax', name='mypredictions')(fc)\n",
    "    model = Model(inputs=base.input, outputs=mypredictions,name = base.name)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    if locked_layers>len(model.layers):\n",
    "        locked_layers = len(model.layers)\n",
    "    for layer in model.layers[:locked_layers]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[locked_layers:]:\n",
    "        layer.trainable = True \n",
    "\n",
    "    return model\n",
    "#vgg16 xception inception_resnet_v2 inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "mypredictions (Dense)        (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 14,719,818\n",
      "Trainable params: 14,719,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "mypredictions (Dense)        (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 14,719,818\n",
      "Trainable params: 14,719,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16\n",
    "model = create_model(b_model=base_model, n_classes = 10, set_weights = None, locked_layers=locked_layers, input_shape=(224,224,3), include_top=False)   \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epoch = 100\n",
    "learning_rate = 0.01\n",
    "locked_layers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2489/2489 [00:12<00:00, 196.68it/s]\n",
      "100%|██████████| 2267/2267 [00:11<00:00, 204.58it/s]\n",
      "100%|██████████| 2317/2317 [00:11<00:00, 206.88it/s]\n",
      "100%|██████████| 2346/2346 [00:11<00:00, 205.02it/s]\n",
      "100%|██████████| 2326/2326 [00:11<00:00, 205.21it/s]\n",
      "100%|██████████| 2312/2312 [00:11<00:00, 204.58it/s]\n",
      "100%|██████████| 2325/2325 [00:11<00:00, 203.94it/s]\n",
      "100%|██████████| 2002/2002 [00:09<00:00, 205.16it/s]\n",
      "100%|██████████| 1911/1911 [00:09<00:00, 207.62it/s]\n",
      "100%|██████████| 2129/2129 [00:10<00:00, 206.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17939, 224, 224, 3)\n",
      "y_train shape: (17939, 10)\n",
      "X_val shape: (4485, 224, 224, 3)\n",
      "y_val shape: (4485, 10)\n"
     ]
    }
   ],
   "source": [
    "trian_set_path=os.path.join('datasets','train')\n",
    "\n",
    "X, y = load_train_data(trian_set_path,size = (224,224))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=35)\n",
    "\n",
    "# One hot encoding of the classes\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)#\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_val shape:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17939 samples, validate on 4485 samples\n",
      "Epoch 1/100\n",
      "17939/17939 [==============================] - 96s 5ms/step - loss: 14.5021 - acc: 0.0955 - val_loss: 14.4829 - val_acc: 0.1014\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 14.48293, saving model to saved_models/vgg16weights.01-14.48.hdf5\n",
      "Epoch 2/100\n",
      "17939/17939 [==============================] - 93s 5ms/step - loss: 14.5942 - acc: 0.0945 - val_loss: 14.4829 - val_acc: 0.1014\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 14.48293\n",
      "Epoch 3/100\n",
      "17939/17939 [==============================] - 93s 5ms/step - loss: 14.5520 - acc: 0.0972 - val_loss: 14.4829 - val_acc: 0.1014\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 14.48293\n",
      "Epoch 4/100\n",
      "17939/17939 [==============================] - 93s 5ms/step - loss: 14.5538 - acc: 0.0971 - val_loss: 14.4829 - val_acc: 0.1014\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 14.48293\n",
      "Training time: 383\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduce_lr2 = ReduceLROnPlateau(monitor='val_loss', patience=3, mode='auto') \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "if not os.path.isdir('saved_models'):\n",
    "    os.mkdir('saved_models')\n",
    "    \n",
    "#models = [VGG16,InceptionResNetV2,Xception,InceptionV3]\n",
    "#models = [VGG16,InceptionResNetV2,Xception]\n",
    "base_model = VGG16\n",
    "#for i in models:\n",
    "model = create_model(b_model=base_model, n_classes = 10, set_weights = None, locked_layers=locked_layers, input_shape=(224,224,3), include_top=False)   \n",
    "    #weights_path = os.path.join('saved_models',model.name+'.weights.best.hdf5')\n",
    "weights_path = os.path.join('saved_models',model.name+'weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, save_best_only=True)\n",
    "\n",
    "s1 = time()\n",
    "history = model.fit(image_preprocess(model.name, X_train), y_train, \n",
    "                    validation_data=(image_preprocess(model.name, X_val), y_val), \n",
    "                    epochs=n_epoch, batch_size=batch_size, callbacks=[checkpointer, early_stopping, reduce_lr2], verbose=1)\n",
    "print(\"Training time: %d\"%(time()-s1))\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "plt.savefig(os.path.join('saved_models',model.name+'_acc.jpg'))\n",
    "    \n",
    "save_model(model, cross=model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
